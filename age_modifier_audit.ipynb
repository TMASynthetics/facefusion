{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def highlight_differences(source_path, transformed_path, output_path):\n",
    "    # Load the images\n",
    "    data_dir =  \"data/tests/\"\n",
    "    source = cv2.imread(os.path.join(data_dir, source_path))\n",
    "    transformed = cv2.imread(os.path.join(data_dir, transformed_path))\n",
    "\n",
    "    # Convert to grayscale for difference computation (optional, can also be done on color)\n",
    "    diff = cv2.absdiff(source, transformed)  # Compute the absolute difference\n",
    "\n",
    "    # Convert difference to grayscale to highlight changes (optional step to create a mask)\n",
    "    diff_gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Threshold the difference to isolate significant changes\n",
    "    _, mask = cv2.threshold(diff_gray, 0, 255, cv2.THRESH_BINARY)  # Adjust the threshold as needed\n",
    "\n",
    "    # Create an overlay to highlight changes\n",
    "    overlay = source.copy()\n",
    "    overlay[mask > 0] = [0, 0, 255]  # Highlight changes in red (for example)\n",
    "\n",
    "    # Blend the overlay with the original image\n",
    "    alpha = 1  # Transparency factor for overlay\n",
    "    highlighted = cv2.addWeighted(overlay, alpha, source, 1 - alpha, 0)\n",
    "\n",
    "    # Save or display the output\n",
    "    cv2.imwrite(os.path.join(data_dir, output_path), highlighted)\n",
    "    #cv2.imshow('Highlighted Differences', highlighted)\n",
    "    #cv2.waitKey(0)\n",
    "    #cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#highlight_differences('source.jpg', 'padding_bottom_minus100.jpg', 'diff_image_negative_padding.jpg')\n",
    "#highlight_differences('conv64_padding_minus100.jpg', 'conv64_padding_plus100.jpg', 'diff_conv.jpg')\n",
    "#highlight_differences('source.jpg', 'mask_blur_1.jpg', 'diff_with_blur_1.jpg')\n",
    "highlight_differences('mask_temp_vision_frame.jpg', 'result.jpg', \"mask_marie_conv128.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source_path = \"source.jpg\"\n",
    "transformed_path = \"1fe397e3.jpg\"\n",
    "source = cv2.imread(source_path)\n",
    "transformed = cv2.imread(transformed_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1024, 1024, 3), (1024, 1024, 3))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ear",
   "language": "python",
   "name": "env_ear"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
